{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import featuretools as ft\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Why does is DFS not creating aggregation features?\n",
    "One common issue you might run into is with aggregation features. You may have created your entityset, and then applied DFS to create features. However, you may be puzzled why no aggreation features were not created. \n",
    "- This is most likely because you have a single table in your entity, and thus DFS is not capable of creating aggregation features. You need at least 2 entities. Featuretools will look for a relationship, and aggregate based on that relationship.\n",
    "\n",
    "Let's look at a simple example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Entityset: customer_data\n",
       "  Entities:\n",
       "    transactions [Rows: 500, Columns: 11]\n",
       "  Relationships:\n",
       "    No relationships"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = ft.demo.load_mock_customer()\n",
    "transactions_df = data[\"transactions\"].merge(data[\"sessions\"]).merge(data[\"customers\"])\n",
    "es = ft.EntitySet(id=\"customer_data\")\n",
    "es = es.entity_from_dataframe(entity_id=\"transactions\",\n",
    "                              dataframe=transactions_df,\n",
    "                              index=\"transaction_id\")\n",
    "es"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice how we only have 1 entity in our entityset. If we try to create aggregation features on this entityset, it will not be possible because aggregation features need 2 entities. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<Feature: session_id>,\n",
       " <Feature: product_id>,\n",
       " <Feature: amount>,\n",
       " <Feature: customer_id>,\n",
       " <Feature: device>,\n",
       " <Feature: zip_code>,\n",
       " <Feature: DAY(transaction_time)>,\n",
       " <Feature: DAY(session_start)>,\n",
       " <Feature: DAY(join_date)>,\n",
       " <Feature: DAY(date_of_birth)>,\n",
       " <Feature: YEAR(transaction_time)>,\n",
       " <Feature: YEAR(session_start)>,\n",
       " <Feature: YEAR(join_date)>,\n",
       " <Feature: YEAR(date_of_birth)>,\n",
       " <Feature: MONTH(transaction_time)>,\n",
       " <Feature: MONTH(session_start)>,\n",
       " <Feature: MONTH(join_date)>,\n",
       " <Feature: MONTH(date_of_birth)>,\n",
       " <Feature: WEEKDAY(transaction_time)>,\n",
       " <Feature: WEEKDAY(session_start)>,\n",
       " <Feature: WEEKDAY(join_date)>,\n",
       " <Feature: WEEKDAY(date_of_birth)>]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_matrix, feature_defs = ft.dfs(entityset=es, target_entity=\"transactions\")\n",
    "feature_defs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "None of the above features are aggregation features. To fix this issue, you can add another entity to your entityset.\n",
    "\n",
    "There is a couple of ways to add an entity to your entityset:\n",
    "\n",
    "**Solution #1 - You can add new entity if you have additional data.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Entityset: customer_data\n",
       "  Entities:\n",
       "    transactions [Rows: 500, Columns: 11]\n",
       "    products [Rows: 5, Columns: 2]\n",
       "  Relationships:\n",
       "    No relationships"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "products_df = data[\"products\"]\n",
    "es = es.entity_from_dataframe(entity_id=\"products\",\n",
    "                              dataframe=products_df,\n",
    "                              index=\"product_id\")\n",
    "es"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice how we now have an additional entity in our entityset.\n",
    "\n",
    "**Solution #2 - You can normalize an existing entity.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Entityset: customer_data\n",
       "  Entities:\n",
       "    transactions [Rows: 500, Columns: 6]\n",
       "    products [Rows: 5, Columns: 2]\n",
       "    sessions [Rows: 35, Columns: 6]\n",
       "  Relationships:\n",
       "    transactions.session_id -> sessions.session_id"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "es = es.normalize_entity(base_entity_id=\"transactions\",\n",
    "                         new_entity_id=\"sessions\",\n",
    "                         index=\"session_id\",\n",
    "                         make_time_index=\"session_start\",\n",
    "                         additional_variables=[\"device\", \"customer_id\", \"zip_code\", \"session_start\", \"join_date\"])\n",
    "es"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice how we have an additional entity in our entityset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<Feature: session_id>,\n",
       " <Feature: product_id>,\n",
       " <Feature: amount>,\n",
       " <Feature: DAY(transaction_time)>,\n",
       " <Feature: DAY(date_of_birth)>,\n",
       " <Feature: YEAR(transaction_time)>,\n",
       " <Feature: YEAR(date_of_birth)>,\n",
       " <Feature: MONTH(transaction_time)>,\n",
       " <Feature: MONTH(date_of_birth)>,\n",
       " <Feature: WEEKDAY(transaction_time)>,\n",
       " <Feature: WEEKDAY(date_of_birth)>,\n",
       " <Feature: sessions.device>,\n",
       " <Feature: sessions.customer_id>,\n",
       " <Feature: sessions.zip_code>,\n",
       " <Feature: sessions.SUM(transactions.amount)>,\n",
       " <Feature: sessions.STD(transactions.amount)>,\n",
       " <Feature: sessions.MAX(transactions.amount)>,\n",
       " <Feature: sessions.SKEW(transactions.amount)>,\n",
       " <Feature: sessions.MIN(transactions.amount)>,\n",
       " <Feature: sessions.MEAN(transactions.amount)>,\n",
       " <Feature: sessions.COUNT(transactions)>]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_matrix, feature_defs = ft.dfs(entityset=es, target_entity=\"transactions\")\n",
    "feature_defs[:-10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have sucessfully created aggregation features, a few of which are:\n",
    "- `<Feature: sessions.SUM(transactions.amount)>`\n",
    "- `<Feature: sessions.STD(transactions.amount)>`\n",
    "- `<Feature: sessions.MAX(transactions.amount)>`\n",
    "- `<Feature: sessions.SKEW(transactions.amount)>`\n",
    "- `<Feature: sessions.MIN(transactions.amount)>`\n",
    "- `<Feature: sessions.MEAN(transactions.amount)>`\n",
    "- `<Feature: sessions.COUNT(transactions)>`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why am I getting this error `AssertionError: Index is not unique on dataframe` ?\n",
    "One error you might run into is with index on your entity. You may have may be trying to create your entity, and running into this error. \n",
    "- This is because each entity in your entityset needs a unique index.\n",
    "\n",
    "Let's look at a simple example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>4.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  rating\n",
       "0   1     3.5\n",
       "1   2     4.0\n",
       "2   3     4.5\n",
       "3   4     1.5\n",
       "4   4     5.0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "product_df = pd.DataFrame({'id': [1, 2, 3, 4, 4],\n",
    "                           'rating': [3.5, 4.0, 4.5, 1.5, 5.0]})\n",
    "product_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice how the `id` column has a duplicate index of `4`. If you try to create an entity with this dataframe, you will run into an error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Index is not unique on dataframe (Entity products)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-a6e02ba6fa47>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m es = es.entity_from_dataframe(entity_id=\"products\",\n\u001b[1;32m      3\u001b[0m                               \u001b[0mdataframe\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mproduct_df\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m                               index=\"id\")\n\u001b[0m",
      "\u001b[0;32m~/featuretools/featuretools/entityset/entityset.py\u001b[0m in \u001b[0;36mentity_from_dataframe\u001b[0;34m(self, entity_id, dataframe, index, variable_types, make_index, time_index, secondary_time_index, already_sorted)\u001b[0m\n\u001b[1;32m    645\u001b[0m             \u001b[0msecondary_time_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msecondary_time_index\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    646\u001b[0m             \u001b[0malready_sorted\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0malready_sorted\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 647\u001b[0;31m             make_index=make_index)\n\u001b[0m\u001b[1;32m    648\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mentity_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mentity\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mentity\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    649\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_data_description\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/featuretools/featuretools/entityset/entity.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, id, df, entityset, variable_types, index, time_index, secondary_time_index, last_time_index, already_sorted, make_index, verbose)\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mid\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvariables\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/featuretools/featuretools/entityset/entity.py\u001b[0m in \u001b[0;36mset_index\u001b[0;34m(self, variable_id, unique)\u001b[0m\n\u001b[1;32m    450\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    451\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0munique\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 452\u001b[0;31m             \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_unique\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Index is not unique on dataframe (Entity {})\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    453\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    454\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_variable_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvariable_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIndex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: Index is not unique on dataframe (Entity products)"
     ]
    }
   ],
   "source": [
    "es = ft.EntitySet(id=\"product_data\")\n",
    "es = es.entity_from_dataframe(entity_id=\"products\",\n",
    "                              dataframe=product_df,\n",
    "                              index=\"id\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To fix this issue, you can do a couple of things:\n",
    "\n",
    "**Solution #1 - You can create a unique index on your dataframe.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "product_df = pd.DataFrame({'id': [1, 2, 3, 4, 5],\n",
    "                           'rating': [3.5, 4.0, 4.5, 1.5, 5.0]})\n",
    "product_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "es = es.entity_from_dataframe(entity_id=\"products\",\n",
    "                              dataframe=product_df,\n",
    "                              index=\"id\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Solution #2 - Set `make_index` to True in your call to `entity_from_dataframe` to create a new index on that data**\n",
    "- `make_index` is creates a unique index for each row by just looking at what number the row is, in relation to all the other rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "product_df = pd.DataFrame({'id': [1, 2, 3, 4, 4],\n",
    "                           'rating': [3.5, 4.0, 4.5, 1.5, 5.0]})\n",
    "\n",
    "es = ft.EntitySet(id=\"product_data\")\n",
    "es = es.entity_from_dataframe(entity_id=\"products\",\n",
    "                              dataframe=product_df,\n",
    "                              index=\"product_id\",\n",
    "                              make_index=True)\n",
    "es['products'].df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is the difference between `copy_variables` and `additional_variables`?\n",
    "One function you make run for creating entity is `normalize_entity`. This function creates a new entity, and relationship from unique values of an existing relationships. It has 2 similar, but different arguments (`copy_varaibles` and `additional_variables`). You may be confused as to what the difference is between these two arguments:\n",
    "\n",
    "- `additional_variables` will remove variables from the base entity, and move them to the new entity. \n",
    "- `copy_variables` will keep the variables in the base entity, and copy them to the new entity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame({'product_id': [1, 2, 3, 4, 5],\n",
    "                     'os': ['android', 'ios', 'android', 'ios', 'windows'],\n",
    "                     'storage': [64, 32, 64, 32, 16],\n",
    "                     'price': [900, 1000, 800, 900, 1000], \n",
    "                     'rating': [3.5, 4.0, 4.5, 1.5, 5.0]})\n",
    "\n",
    "es = ft.EntitySet(id=\"product_data\")\n",
    "es = es.entity_from_dataframe(entity_id=\"products\",\n",
    "                              dataframe=data,\n",
    "                              index=\"product_id\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we normalize to create a new entity, let's look at base entity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "es['products'].df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice the columns `storage`, and `price` columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "es = es.normalize_entity(base_entity_id=\"products\",\n",
    "                         new_entity_id=\"device\",\n",
    "                         index=\"os\",\n",
    "                         additional_variables=[\"storage\"],\n",
    "                         copy_variables=[\"price\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We normalized the columns to create a new entity. \n",
    "- For `additional_variables`, `storage` will be removed from the `products` entity, and moved to the new `device` entity. \n",
    "- For `copy_variables`, `price` will be copied from the `products` entity to the new `device` entity. \n",
    "\n",
    "Let's see this in the actual Entityset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "es['products'].df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice above how `price` is still in the products entity, while `storage` is not. It has been moved to the `device` entity, as seen below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "es['device'].df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How do I get a list of all Aggregation and Transform primitives?\n",
    "\n",
    "You can do `featuretools.list_primitives()` to get all the primitive in featuretools. It will return a dataframe with the names, type, and description of the primitives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_primitives = ft.list_primitives()\n",
    "df_primitives.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_primitives.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can take the `name` column and provide that directly to `ft.dfs`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregation_primitives = df_primitives[df_primitives['type'] == 'aggregation']['name'].tolist()\n",
    "aggregation_primitives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_primitives = df_primitives[df_primitives['type'] == 'transform']['name'].tolist()\n",
    "transform_primitives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How do I change the units for a TimeSince primitive?\n",
    "There are a few primitives in featuretools that make some time-based calculation. These include `TimeSince, TimeSincePrevious, TimeSinceLast, TimeSinceFirst`. BY "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from featuretools.primitives import TimeSince, TimeSincePrevious, TimeSinceLast, TimeSinceFirst\n",
    "\n",
    "time_since = TimeSince(unit=\"minutes\")\n",
    "time_since_previous = TimeSincePrevious(unit=\"hours\")\n",
    "time_since_last = TimeSinceLast(unit=\"days\")\n",
    "time_since_first = TimeSinceFirst(unit=\"years\")\n",
    "\n",
    "es = ft.demo.load_mock_customer(return_entityset=True)\n",
    "\n",
    "feature_matrix, feature_defs = ft.dfs(entityset=es,\n",
    "                                      target_entity=\"customers\",\n",
    "                                      agg_primitives=[time_since_last, time_since_first],\n",
    "                                      trans_primitives=[time_since, time_since_previous])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can see that our feature matrix contains multiple features where the units for te TimeSince primitives are changed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>zip_code</th>\n",
       "      <th>TIME_SINCE_LAST(sessions.session_start, unit=days)</th>\n",
       "      <th>TIME_SINCE_FIRST(sessions.session_start, unit=years)</th>\n",
       "      <th>TIME_SINCE_LAST(transactions.transaction_time, unit=days)</th>\n",
       "      <th>TIME_SINCE_FIRST(transactions.transaction_time, unit=years)</th>\n",
       "      <th>TIME_SINCE_PREVIOUS(join_date, unit=hours)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>customer_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>60091</td>\n",
       "      <td>1994.429033</td>\n",
       "      <td>5.464230</td>\n",
       "      <td>1994.417748</td>\n",
       "      <td>5.464230</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13244</td>\n",
       "      <td>1994.386903</td>\n",
       "      <td>5.464314</td>\n",
       "      <td>1994.377875</td>\n",
       "      <td>5.464314</td>\n",
       "      <td>8748.708611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13244</td>\n",
       "      <td>1994.363581</td>\n",
       "      <td>5.464125</td>\n",
       "      <td>1994.352296</td>\n",
       "      <td>5.464125</td>\n",
       "      <td>-5911.808333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>60091</td>\n",
       "      <td>1994.504264</td>\n",
       "      <td>5.464261</td>\n",
       "      <td>1994.497493</td>\n",
       "      <td>5.464261</td>\n",
       "      <td>-3043.572222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>60091</td>\n",
       "      <td>1994.392921</td>\n",
       "      <td>5.464281</td>\n",
       "      <td>1994.387655</td>\n",
       "      <td>5.464281</td>\n",
       "      <td>-6374.673333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            zip_code  TIME_SINCE_LAST(sessions.session_start, unit=days)  \\\n",
       "customer_id                                                                \n",
       "1              60091                                        1994.429033    \n",
       "2              13244                                        1994.386903    \n",
       "3              13244                                        1994.363581    \n",
       "4              60091                                        1994.504264    \n",
       "5              60091                                        1994.392921    \n",
       "\n",
       "             TIME_SINCE_FIRST(sessions.session_start, unit=years)  \\\n",
       "customer_id                                                         \n",
       "1                                                     5.464230      \n",
       "2                                                     5.464314      \n",
       "3                                                     5.464125      \n",
       "4                                                     5.464261      \n",
       "5                                                     5.464281      \n",
       "\n",
       "             TIME_SINCE_LAST(transactions.transaction_time, unit=days)  \\\n",
       "customer_id                                                              \n",
       "1                                                  1994.417748           \n",
       "2                                                  1994.377875           \n",
       "3                                                  1994.352296           \n",
       "4                                                  1994.497493           \n",
       "5                                                  1994.387655           \n",
       "\n",
       "             TIME_SINCE_FIRST(transactions.transaction_time, unit=years)  \\\n",
       "customer_id                                                                \n",
       "1                                                     5.464230             \n",
       "2                                                     5.464314             \n",
       "3                                                     5.464125             \n",
       "4                                                     5.464261             \n",
       "5                                                     5.464281             \n",
       "\n",
       "             TIME_SINCE_PREVIOUS(join_date, unit=hours)  \n",
       "customer_id                                              \n",
       "1                                                   NaN  \n",
       "2                                           8748.708611  \n",
       "3                                          -5911.808333  \n",
       "4                                          -3043.572222  \n",
       "5                                          -6374.673333  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_matrix.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
